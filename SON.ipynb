{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec3f523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd8191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the file using Pandas and changing into DataFrame\n",
    "file = pd.read_csv(\"retail.txt\", names=['items'], dtype=object)\n",
    "\n",
    "# Removing \"\\n\" values from the data\n",
    "for i in file.index:\n",
    "    file.iloc[i]['items'] = file.iloc[i]['items'].split(\" \")\n",
    "    del file.iloc[i]['items'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac9a737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = file.sample(frac=0.0005, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85c7d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the apriori algorithm create previously.\n",
    "# %load apy.py\n",
    "# importing the necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from itertools import combinations\n",
    "\n",
    "# reading the file using Pandas and changing into DataFrame\n",
    "file = pd.read_csv(\"retail.txt\", names=['items'], dtype=object)\n",
    "\n",
    "# Removing \"\\n\" values from the data\n",
    "for i in file.index:\n",
    "    file.iloc[i]['items'] = file.iloc[i]['items'].split(\" \")\n",
    "    del file.iloc[i]['items'][-1]\n",
    "\n",
    "# function to create frequent itemset from candidate set\n",
    "def createFrequentItemSet(candidate_set, min_support):\n",
    "    # creating an empty DataFrame\n",
    "    frequent_itemset = pd.DataFrame(columns=['support'])\n",
    "    \n",
    "    # iterating through the candidate set\n",
    "    for item in candidate_set.index:\n",
    "        # checking if the support of the item is >= min_support and putting them in frequent itemset\n",
    "        if (candidate_set.loc[item]['support'] >= min_support):\n",
    "            frequent_itemset.loc[item, 'support'] = candidate_set.loc[item, 'support']\n",
    "\n",
    "    return frequent_itemset\n",
    "\n",
    "# function to create frequent itemset of pairs from candidate set containing pairs\n",
    "def createFrequentItemSet2(candidate_set, min_support):\n",
    "    #creating an empty DataFrame\n",
    "    frequent_itemset = pd.DataFrame(columns=['items', 'support'])\n",
    "    \n",
    "    # iterating through candidate_set\n",
    "    for item in candidate_set.index:\n",
    "        # checking the support of pair with min_support\n",
    "        if (candidate_set.loc[item, 'support'] >= min_support):\n",
    "            frequent_itemset.loc[item, 'support'] = candidate_set.loc[item, 'support']\n",
    "            frequent_itemset.loc[item, 'items'] = candidate_set.loc[item, 'items']\n",
    "\n",
    "    return frequent_itemset\n",
    "\n",
    "# function to check if the pair of items are in the basket\n",
    "def isSubset(bigger_array, smaller_array):\n",
    "    isSubset = True\n",
    "    for i in smaller_array:\n",
    "        if i in bigger_array:\n",
    "            continue\n",
    "        else:\n",
    "            isSubset = False\n",
    "            break\n",
    "\n",
    "    return isSubset\n",
    "\n",
    "# function to create pair from the frequent itemset\n",
    "def createPairs(frequent_itemset):\n",
    "    index_array = frequent_itemset.index\n",
    "    candidate_set = pd.DataFrame(columns=['items', 'support'])\n",
    "    \n",
    "    #using combinations from itertools to create pairs\n",
    "    pairs = list(combinations(index_array, 2))\n",
    "    pair_df = pd.DataFrame(columns=['items', 'support'])\n",
    "    \n",
    "    index = 0\n",
    "    for i in range(len(pairs)):\n",
    "            pair_df.loc[i,'items'] = pairs[i]\n",
    "            pair_df.loc[i,'support'] = 0\n",
    "            candidate_set = pd.concat([candidate_set, pair_df])\n",
    "            index += 1\n",
    "            pair_df.drop(pair_df.index, inplace=True)\n",
    "    \n",
    "    return candidate_set\n",
    "\n",
    "#function implementing apriori algorithm\n",
    "def Apriori(transactions, min_support) -> pd.DataFrame:\n",
    "    candidate_set = pd.DataFrame(columns=['support'])\n",
    "    \n",
    "    # iterating through the baskets to create candidate set with the support of individual items\n",
    "    for i in transactions.index:\n",
    "        for item in transactions['items'][i]:\n",
    "            if item in candidate_set.index:\n",
    "                candidate_set.at[item, 'support'] += 1\n",
    "            else:\n",
    "                df2 = pd.DataFrame(columns=['support'])\n",
    "                df2.loc[item, 'support'] = 1 \n",
    "                candidate_set = pd.concat([candidate_set, df2])\n",
    "                \n",
    "\n",
    "    # calling createFrequentItemSet to create a frequent itemset\n",
    "    frequent_itemset = createFrequentItemSet(candidate_set, min_support)\n",
    "\n",
    "    # creating pairs from frequent itemset\n",
    "    candidate_set = createPairs(frequent_itemset)\n",
    "\n",
    "    # clearing frequent_itemset\n",
    "    frequent_itemset.drop(frequent_itemset.index, inplace=True)\n",
    "\n",
    "    # creating support of the pairs in the candidate_set\n",
    "    for i in candidate_set.index:\n",
    "        for j in transactions.index:\n",
    "            if isSubset(transactions.loc[j]['items'], candidate_set.loc[i]['items']):\n",
    "                candidate_set.iloc[i]['support'] += 1\n",
    "\n",
    "    # using createFrequentItemsSet2 to create frequent itemset containing pairs.\n",
    "    frequent_itemset = createFrequentItemSet2(candidate_set, min_support)\n",
    "\n",
    "    return frequent_itemset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7fbbdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to divide dataframes into smaller chunks\n",
    "def split_dataframe_by_position(df, splits):\n",
    "    \"\"\"\n",
    "    Takes a dataframe and an integer of the number of splits to create.\n",
    "    Returns a list of dataframes.\n",
    "    \"\"\"\n",
    "    dataframes = []\n",
    "    index_to_split = len(df) // splits\n",
    "    start = 0\n",
    "    end = index_to_split\n",
    "    for split in range(splits):\n",
    "        temporary_df = df.iloc[start:end, :]\n",
    "        dataframes.append(temporary_df)\n",
    "        start += index_to_split\n",
    "        end += index_to_split\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create frequent itemset using user_inputted support\n",
    "def createFrequentItemSet3(candidate_set: pd.DataFrame, min_support: int) -> pd.DataFrame:\n",
    "    freq = pd.DataFrame(columns=['items', 'support'])\n",
    "    candidate_set = candidate_set.infer_objects()\n",
    "    for i in candidate_set.index:\n",
    "        support = candidate_set.iloc[i]['support']\n",
    "        if (support >= min_support):\n",
    "            freq.loc[i] = candidate_set.loc[i]\n",
    "            #freq.loc[i, 'support'] = support\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58292a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SON algorithm implementation\n",
    "def SON(transactions: pd.DataFrame, min_support: int) -> pd.DataFrame:\n",
    "    # defining the number of chunks\n",
    "    num_chunks = 20\n",
    "\n",
    "    #dividing the user_input data into chuncks\n",
    "    chunks = split_dataframe_by_position(transactions, num_chunks)\n",
    "\n",
    "    #recalculating user_support for chunks processing\n",
    "    chunk_support = math.ceil(min_support/num_chunks)\n",
    "\n",
    "    # creating an empty dataframe\n",
    "    candidate_itemset = pd.DataFrame(columns=['items', 'support'])\n",
    "    \n",
    "    # for loop to process individual chunks\n",
    "    for i in range(len(chunks)):\n",
    "        # using Apriori algorithm on individual chunks and adding the results to candidate set\n",
    "        candidates = Apriori(chunks[i], chunk_support)\n",
    "        candidate_itemset = pd.concat([candidate_itemset, candidates], ignore_index=True)\n",
    "    \n",
    "    #print(candidate_itemset)\n",
    "    # Pass 2\n",
    "    # finding actual supports of the candidate set, thus reducing false negative\n",
    "    # generated in the first pass.\n",
    "    for i in candidate_itemset.index:\n",
    "        for j in transactions.index:\n",
    "            if isSubset(transactions.loc[j]['items'], candidate_itemset.loc[i]['items']):\n",
    "                candidate_itemset.iloc[i]['support'] += 1\n",
    "\n",
    "    \n",
    "    freq = createFrequentItemSet3(candidate_itemset, min_support)\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d952028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.00025773048401\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "freq = SON(data, 2)\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61a2f854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               items support\n",
      "0          (39, 185)       2\n",
      "1          (39, 664)       2\n",
      "2          (39, 710)       2\n",
      "3         (39, 1426)       2\n",
      "4         (39, 3236)       3\n",
      "...              ...     ...\n",
      "3108   (2528, 13309)       2\n",
      "3109   (2528, 13621)       2\n",
      "3110  (10587, 13309)       2\n",
      "3111  (10587, 13621)       2\n",
      "3112  (13309, 13621)       2\n",
      "\n",
      "[3113 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04871bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
