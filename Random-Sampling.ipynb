{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec3f523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from itertools import combinations\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dd8191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the file using Pandas and changing into DataFrame\n",
    "file = pd.read_csv(\"retail.txt\", names=['items'], dtype=object)\n",
    "\n",
    "# Removing \"\\n\" values from the data\n",
    "for i in file.index:\n",
    "    file.iloc[i]['items'] = file.iloc[i]['items'].split(\" \")\n",
    "    del file.iloc[i]['items'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d919071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load apy.py\n",
    "# importing the necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from itertools import combinations\n",
    "\n",
    "# function to create frequent itemset from candidate set\n",
    "def createFrequentItemSet(candidate_set, min_support):\n",
    "    # creating an empty DataFrame\n",
    "    frequent_itemset = pd.DataFrame(columns=['support'])\n",
    "    \n",
    "    # iterating through the candidate set\n",
    "    for item in candidate_set.index:\n",
    "        # checking if the support of the item is >= min_support and putting them in frequent itemset\n",
    "        if (candidate_set.loc[item]['support'] >= min_support):\n",
    "            frequent_itemset.loc[item, 'support'] = candidate_set.loc[item, 'support']\n",
    "\n",
    "    return frequent_itemset\n",
    "\n",
    "# function to create frequent itemset of pairs from candidate set containing pairs\n",
    "def createFrequentItemSet2(candidate_set, min_support):\n",
    "    #creating an empty DataFrame\n",
    "    frequent_itemset = pd.DataFrame(columns=['items', 'support'])\n",
    "    \n",
    "    # iterating through candidate_set\n",
    "    for item in candidate_set.index:\n",
    "        # checking the support of pair with min_support\n",
    "        if (candidate_set.loc[item, 'support'] >= min_support):\n",
    "            frequent_itemset.loc[item, 'support'] = candidate_set.loc[item, 'support']\n",
    "            frequent_itemset.loc[item, 'items'] = candidate_set.loc[item, 'items']\n",
    "\n",
    "    return frequent_itemset\n",
    "\n",
    "# function to check if the pair of items are in the basket\n",
    "def isSubset(bigger_array, smaller_array):\n",
    "    isSubset = True\n",
    "    for i in smaller_array:\n",
    "        if i in bigger_array:\n",
    "            continue\n",
    "        else:\n",
    "            isSubset = False\n",
    "            break\n",
    "\n",
    "    return isSubset\n",
    "\n",
    "# function to create pair from the frequent itemset\n",
    "def createPairs(frequent_itemset):\n",
    "    index_array = frequent_itemset.index\n",
    "    candidate_set = pd.DataFrame(columns=['items', 'support'])\n",
    "    \n",
    "    #using combinations from itertools to create pairs\n",
    "    pairs = list(combinations(index_array, 2))\n",
    "    pair_df = pd.DataFrame(columns=['items', 'support'])\n",
    "    \n",
    "    index = 0\n",
    "    for i in range(len(pairs)):\n",
    "            pair_df.loc[i,'items'] = pairs[i]\n",
    "            pair_df.loc[i,'support'] = 0\n",
    "            candidate_set = pd.concat([candidate_set, pair_df])\n",
    "            index += 1\n",
    "            pair_df.drop(pair_df.index, inplace=True)\n",
    "    \n",
    "    return candidate_set\n",
    "\n",
    "#function implementing apriori algorithm\n",
    "def Apriori(transactions, min_support) -> pd.DataFrame:\n",
    "    candidate_set = pd.DataFrame(columns=['support'])\n",
    "    \n",
    "    # iterating through the baskets to create candidate set with the support of individual items\n",
    "    for i in transactions.index:\n",
    "        for item in transactions['items'][i]:\n",
    "            if item in candidate_set.index:\n",
    "                candidate_set.at[item, 'support'] += 1\n",
    "            else:\n",
    "                df2 = pd.DataFrame(columns=['support'])\n",
    "                df2.loc[item, 'support'] = 1 \n",
    "                candidate_set = pd.concat([candidate_set, df2])\n",
    "                \n",
    "\n",
    "    # calling createFrequentItemSet to create a frequent itemset\n",
    "    frequent_itemset = createFrequentItemSet(candidate_set, min_support)\n",
    "\n",
    "    # creating pairs from frequent itemset\n",
    "    candidate_set = createPairs(frequent_itemset)\n",
    "\n",
    "    # clearing frequent_itemset\n",
    "    frequent_itemset.drop(frequent_itemset.index, inplace=True)\n",
    "\n",
    "    # creating support of the pairs in the candidate_set\n",
    "    for i in candidate_set.index:\n",
    "        for j in transactions.index:\n",
    "            if isSubset(transactions.loc[j]['items'], candidate_set.loc[i]['items']):\n",
    "                candidate_set.iloc[i]['support'] += 1\n",
    "\n",
    "    # using createFrequentItemsSet2 to create frequent itemset containing pairs.\n",
    "    frequent_itemset = createFrequentItemSet2(candidate_set, min_support)\n",
    "\n",
    "    return frequent_itemset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58292a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function implementing apriori algorithm\n",
    "def Random_Sampling(transactions: pd.DataFrame, min_support: int):\n",
    "    \n",
    "    # using random number generator to get starting and ending indices.\n",
    "    max_num = len(transactions.index)\n",
    "    start = random.randint(0,max_num-2)\n",
    "    end = random.randint(start+1, max_num-1)\n",
    "    support = math.ceil(min_support/125)\n",
    "    dataset = transactions.iloc[start:end,:]\n",
    "    \n",
    "    #using Apriori to get frequent items from random sample\n",
    "    freq = Apriori(dataset, support)\n",
    "    pass1_items = len(freq.index)\n",
    "\n",
    "    candidate_set = pd.DataFrame(columns=['items','support'])\n",
    "    candidate_set = pd.concat([candidate_set, freq], ignore_index=True)\n",
    "    candidate_set.rename(columns={'0':'items'})\n",
    "    candidate_set['support'] = 0\n",
    "    # Pass2: find support of the frequent items against the whole dataset\n",
    "    for i in candidate_set.index:\n",
    "        for j in transactions.index:\n",
    "            if isSubset(transactions.iloc[j]['items'], candidate_set.iloc[i]['items']):\n",
    "                candidate_set.at[i, 'support'] += 1\n",
    "\n",
    "    final = pd.DataFrame(columns=['items','support'])\n",
    "\n",
    "    # iterating through candidate_set\n",
    "    for item in candidate_set.index:\n",
    "        # checking the support of pair with min_support\n",
    "        if (candidate_set.loc[item, 'support'] >= min_support):\n",
    "            freq = pd.DataFrame(columns=['items', 'support'])\n",
    "            freq.loc[item, 'support'] = candidate_set.loc[item, 'support']\n",
    "            freq.loc[item, 'items'] = candidate_set.loc[item, 'items']\n",
    "            final = pd.concat([final, freq], ignore_index=True)\n",
    "            \n",
    "    pass2_items = len(final)\n",
    "    return final, (pass1_items - pass2_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c332d13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = file.sample(frac=0.0002, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d952028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.791614055633545\n"
     ]
    }
   ],
   "source": [
    "# using time.time() to calculate the time taken by the algorithm to execute\n",
    "start_time = time.time()\n",
    "freq, num_false_positives = Random_Sampling(data, 2)\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61a2f854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         items support\n",
      "0     (39, 38)       3\n",
      "1     (39, 48)       6\n",
      "2    (39, 589)       2\n",
      "3     (39, 41)       2\n",
      "4    (39, 475)       2\n",
      "5   (39, 2187)       2\n",
      "6    (48, 589)       2\n",
      "7     (48, 41)       2\n",
      "8    (48, 475)       3\n",
      "9   (48, 2187)       2\n",
      "10  (41, 2187)       2\n",
      "370\n"
     ]
    }
   ],
   "source": [
    "print(freq)\n",
    "print(num_false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd85d676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
